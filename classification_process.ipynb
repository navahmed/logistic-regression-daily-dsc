{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The National Health Service has determined that decisive action to treat diabetes is necessary. However, diagnosing it takes hours of doctors that are in high demand.<br>\n",
    "\n",
    "Help them to predict who is diabetic and who is not based on data that non-medical stuff can obtain so that you reduce the number of people who:\n",
    "- get treated without needing it\n",
    "- don't get treated when they actually needed it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://data.world/data-society/pima-indians-diabetes-database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('pima-indians-diabetes.csv')\n",
    "print(df.shape)\n",
    "\n",
    "df.head()\n",
    "\n",
    "df['Outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  \n",
       "0                     0.627   50  \n",
       "1                     0.351   31  \n",
       "2                     0.672   32  \n",
       "3                     0.167   21  \n",
       "4                     2.288   33  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('Outcome',axis=1)\n",
    "y = df['Outcome']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split your X data in train and test datasets\n",
    "Here is the documentation: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My initial training set is (614, 8) while my initial test set data is (154, 8)\n",
      "My initial dependant variable is (614,) while my test dependant variable is (154,)\n"
     ]
    }
   ],
   "source": [
    "# initial split between training set and validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_f, X_test, y_train_f, Y_test = train_test_split (X, y, test_size = .2, random_state = 45)\n",
    "\n",
    "print(f\"My initial training set is {X_train_f.shape} while my initial test set data is {X_test.shape}\")\n",
    "print(f\"My initial dependant variable is {y_train_f.shape} while my test dependant variable is {Y_test.shape}\")\n",
    "\n",
    "\n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split your train data in train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My initial training set is (491, 8) while my validation test set data is (123, 8)\n",
      "My initial dependant variable is (491,) while my validation dependant variable is (123,)\n"
     ]
    }
   ],
   "source": [
    "# splitting again the initial training data into sub-training data and validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_validation, y_train, Y_validation = train_test_split (X_train_f, y_train_f, test_size = .2, random_state = 45)\n",
    "\n",
    "print(f\"My initial training set is {X_train.shape} while my validation test set data is {X_validation.shape}\")\n",
    "print(f\"My initial dependant variable is {y_train.shape} while my validation dependant variable is {Y_validation.shape}\")\n",
    "# \n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the 3 datasets using StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(491, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "# intitiating the scaler\n",
    "ss = StandardScaler()\n",
    "\n",
    "# fitting and transforming the training,validaton and test set\n",
    "ss.fit_transform(X_train)\n",
    "ss.transform(X_validation)\n",
    "ss.transform(X_test)\n",
    "\n",
    "ss.fit_transform(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling and Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a logistic regression model with NO regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000000, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(C = 1000000, solver = 'lbfgs')\n",
    "log_reg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure the accuracy and ROC_AUC of your model\n",
    "Here is the documentation: https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My accuracy score for the training dataset iss 0.77\n",
      "My ROC_AUC score for the training dataset iss 0.86\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# calculating predicted values for my logistic regression\n",
    "y_predicted = log_reg.predict(X_train)\n",
    "\n",
    "# calculating the probability of someone being positive based on our model and making it as a single np array\n",
    "train_prob = log_reg.predict_proba(X_train)[:,1]\n",
    "\n",
    "# actually calculating accuracy and roc_auc\n",
    "accuracy_scoring = accuracy_score(y_train,y_predicted)\n",
    "roc_scoring = roc_auc_score(y_train,train_prob)\n",
    "\n",
    "print(f'My accuracy score for the training dataset iss {accuracy_scoring.round(2)}')\n",
    "print(f'My ROC_AUC score for the training dataset iss {roc_scoring.round(2)}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a logistic regression model with L1 regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying a l1 regularisation \n",
    "log_lasso = LogisticRegression(penalty = 'l1', solver = 'liblinear')\n",
    "log_lasso.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure the accuracy and ROC_AUC of your model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My lasso model accuracy score for the training dataset iss 0.77\n",
      "My lasso ROC_AUC score for the training dataset iss 0.86\n"
     ]
    }
   ],
   "source": [
    "# # calculating predicted values for my logistic regression\n",
    "y_predicted_l = log_lasso.predict(X_train)\n",
    "\n",
    "# calculating the probability of someone being positive based on our model and making it as a single np array\n",
    "train_prob_l = log_lasso.predict_proba(X_train)[:,1]\n",
    "\n",
    "# actually calculating accuracy and roc_auc\n",
    "accuracy_scoring_l = accuracy_score(y_train,y_predicted_l)\n",
    "roc_scoring_l = roc_auc_score(y_train,train_prob_l)\n",
    "\n",
    "print(f'My lasso model accuracy score for the training dataset iss {accuracy_scoring_l.round(2)}')\n",
    "print(f'My lasso ROC_AUC score for the training dataset iss {roc_scoring_l.round(2)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which model did you choose? Explain your reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would choose a model with higher ROC and less accuracy. **In this case L1 Lasso**.\n",
    "Accuracy is just the measure of how many times we guessed right against the whole population.\n",
    "However, it doesn't take into account the false negative aspect of counting which in this situation is important as we would miss out on people with diabetes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interprete your winning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract your intercept and coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " My coefficients are [[ 0.06819506  0.03774622 -0.02272611  0.01467206 -0.00222092  0.09063562\n",
      "   0.64314139  0.03156812]], Intercept is [-8.39510144]\n"
     ]
    }
   ],
   "source": [
    "coefficients  = log_lasso.coef_\n",
    "intercept = log_lasso.intercept_\n",
    "\n",
    "print(f' My coefficients are {coefficients}, Intercept is {intercept}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the difference in probabilities when changing the value of one of your predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.   0.   0.   0.   0.   0.   0.42 0.23 0.14 0.   0.07 0.23 0.   0.02\n",
      " 0.28 0.43 0.   0.   0.   0.   0.   0.13 0.   0.   0.18 0.   0.04 0.13\n",
      " 0.   0.24 0.   0.   0.   0.   0.17 0.   0.   0.   0.08 0.05 0.21 0.05\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.08 0.38 0.13 0.12 0.22\n",
      " 0.   0.04 0.27 0.   0.   0.48 0.42 0.   0.   0.04 0.22 0.05 0.   0.47\n",
      " 0.19 0.   0.   0.25 0.   0.36 0.9  0.   0.   0.   0.13 0.42 0.07 0.16\n",
      " 0.02 0.   0.06 0.15 0.48 0.   0.16 0.   0.   0.48 0.   0.   0.07 0.\n",
      " 0.   0.   0.22 0.04 0.06 0.   0.   0.11 0.   0.43 0.   0.19 0.07 0.\n",
      " 0.54 0.08 0.   0.   0.18 0.   0.05 0.   0.   0.01 0.   0.   0.   0.\n",
      " 0.   0.14 0.09 0.16 0.06 0.   0.36 0.35 0.   0.   0.07 0.28 0.   0.\n",
      " 0.   0.27 0.14 0.   0.1  0.   0.   0.   0.23 0.   0.   0.17 0.01 0.\n",
      " 0.   0.01 0.02 0.   0.21 0.23 0.   0.12 0.36 0.   0.1  0.   0.   0.\n",
      " 0.1  0.   0.   0.   0.01 0.23 0.29 0.   0.18 0.21 0.   0.   0.03 0.27\n",
      " 0.25 0.29 0.   0.   0.36 0.21 0.02 0.   0.28 0.   0.   0.   0.   0.04\n",
      " 0.02 0.   0.   0.23 0.13 0.16 0.1  0.   0.   0.28 0.   0.62 0.62 0.\n",
      " 0.   0.05 0.   0.1  0.22 0.   0.26 0.   0.08 0.14 0.03 0.   0.06 0.\n",
      " 0.26 0.3  0.   0.23 0.   0.   0.65 0.   0.   0.49 0.18 0.   0.   0.04\n",
      " 0.01 0.01 0.   0.08 0.02 0.   0.   0.19 0.03 0.   0.35 0.29 0.37 0.\n",
      " 0.25 0.   0.   0.26 0.01 0.03 0.54 0.31 0.01 0.   0.12 0.   0.24 0.\n",
      " 0.   0.33 0.03 0.   0.   0.77 0.   0.68 0.   0.   0.   0.03 0.02 0.17\n",
      " 0.06 0.01 0.   0.09 0.3  0.   0.   0.31 0.   0.11 0.46 0.   0.   0.05\n",
      " 0.   0.14 0.   0.   0.03 0.   0.   0.05 0.06 0.18 0.   0.   0.   0.68\n",
      " 0.   0.   0.   0.44 0.   0.   0.56 0.02 0.15 0.   0.17 0.03 0.2  0.\n",
      " 0.02 0.   0.   0.17 0.   0.02 0.29 0.02 0.07 0.   0.43 0.   0.   0.01\n",
      " 0.   0.   0.   0.13 0.46 0.   0.01 0.13 0.18 0.2  0.34 0.23 0.25 0.\n",
      " 0.   0.   0.   0.   0.19 0.   0.06 0.   0.   0.   0.   0.36 0.68 0.\n",
      " 0.16 0.09 0.12 0.07 0.   0.   0.12 0.39 0.   0.   0.   0.13 0.   0.08\n",
      " 0.   0.11 0.1  0.   0.17 0.07 0.38 0.08 0.   0.01 0.   0.34 0.   0.28\n",
      " 0.   0.16 0.   0.   0.   0.07 0.79 0.14 0.   0.   0.   0.15 0.09 0.\n",
      " 0.06 0.1  0.   0.   0.19 0.   0.05 0.27 0.   0.39 0.34 0.   0.   0.26\n",
      " 0.   0.1  0.27 0.28 0.04 0.22 0.1  0.   0.14 0.11 0.   0.   0.04 0.\n",
      " 0.31 0.02 0.09 0.   0.   0.   0.   0.   0.   0.22 0.   0.08 0.   0.\n",
      " 0.16 0.17 0.   0.   0.   0.3  0.   0.   0.   0.   0.   0.01 0.   0.\n",
      " 0.04 0.   0.   0.03 0.15 0.24 0.8  0.   0.06 0.   0.42 0.   0.07 0.18\n",
      " 0.   0.   0.12 0.   0.   0.04 0.   0.   0.   0.41 0.24 0.02 0.   0.1\n",
      " 0.56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# initial probability for patients calculated by the lasso model\n",
    "\n",
    "X_train['Insulin'] = X_train['Insulin'] *5\n",
    "train_prob_l_2 = log_lasso.predict_proba(X_train)[:,1]\n",
    "\n",
    "# differences anywhere there was some data available for Insulin\n",
    "print(train_prob_l.round(2) - train_prob_l_2.round(2))\n",
    "\n",
    "# changing the dataset back to original data\n",
    "X_train['Insulin'] = X_train['Insulin'] /5\n",
    "\n",
    "\n",
    "\n",
    "# \n",
    "# \n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the probability of a positive for your validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.272461  , 0.21215956, 0.09967521, 0.09903868, 0.05292768,\n",
       "       0.46663825, 0.58648439, 0.33781434, 0.05701316, 0.47153603,\n",
       "       0.06790356, 0.54018931, 0.25009996, 0.43990249, 0.77075351,\n",
       "       0.0714337 , 0.10226516, 0.26797398, 0.042863  , 0.62247493,\n",
       "       0.19330454, 0.05211103, 0.24029727, 0.07938276, 0.15049673,\n",
       "       0.17461892, 0.26714813, 0.21026371, 0.1026948 , 0.00372388,\n",
       "       0.37247738, 0.24992262, 0.0389421 , 0.20274177, 0.86309256,\n",
       "       0.02423544, 0.1619096 , 0.33728958, 0.1026319 , 0.08095139,\n",
       "       0.1576813 , 0.12282049, 0.56750827, 0.17421436, 0.0860804 ,\n",
       "       0.34084853, 0.2419918 , 0.04359395, 0.17176606, 0.14814092,\n",
       "       0.32519829, 0.57038807, 0.44795322, 0.34418954, 0.35450499,\n",
       "       0.0800847 , 0.09746833, 0.08434813, 0.0295791 , 0.23965582,\n",
       "       0.58311658, 0.35059387, 0.10169312, 0.67213135, 0.07307416,\n",
       "       0.32870329, 0.62809424, 0.3938755 , 0.64469841, 0.07156889,\n",
       "       0.11099194, 0.00583028, 0.68774665, 0.14725764, 0.09382356,\n",
       "       0.43137151, 0.5646906 , 0.1135991 , 0.08711958, 0.11412997,\n",
       "       0.11281318, 0.6804755 , 0.20611018, 0.28028176, 0.0932524 ,\n",
       "       0.12168656, 0.82258767, 0.10546747, 0.45427633, 0.61604014,\n",
       "       0.21257921, 0.04870961, 0.89234467, 0.05602892, 0.21225802,\n",
       "       0.69380971, 0.06825518, 0.27905578, 0.05259968, 0.14878492,\n",
       "       0.1189918 , 0.43442976, 0.79108101, 0.14225778, 0.39106118,\n",
       "       0.49915685, 0.02231883, 0.74417028, 0.66704364, 0.15034116,\n",
       "       0.34715998, 0.25847006, 0.10095507, 0.05901919, 0.1009115 ,\n",
       "       0.44430825, 0.14103547, 0.507097  , 0.29641813, 0.13617239,\n",
       "       0.40864787, 0.14892519, 0.36198581])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# still using the lasso logistic regression\n",
    "log_lasso_validation = LogisticRegression(penalty = 'l1', solver= 'liblinear' )\n",
    "log_lasso_validation.fit(X_validation, Y_validation )\n",
    "\n",
    "# calculating probability for the validation set\n",
    "validation_positive_prob =  log_lasso_validation.predict_proba(X_validation)[:,1]\n",
    "validation_positive_prob\n",
    "\n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract FPR, TPR and thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total True Positive are  113\n",
      "Total False Positive are  40\n",
      "Total True Negatives are  266\n",
      "Total False Negatives are  72\n",
      "The False Positive rate for the training data at a 50% threshold is  0.08\n",
      "The True Positive rate for the training data at a 50% threshold is  0.39\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import  roc_curve\n",
    "\n",
    "# function to count all instances \n",
    "\n",
    "def perf_measure(y_actual, y_hat):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "            TP+=1\n",
    "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "            FP +=1\n",
    "        if y_actual[i]==y_hat[i]==0:\n",
    "            TN+=1\n",
    "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "            FN+=1\n",
    "    print('Total True Positive are ', TP) \n",
    "    print('Total False Positive are ', FP)   \n",
    "    print('Total True Negatives are ', TN)   \n",
    "    print('Total False Negatives are ', FN)   \n",
    "\n",
    "    return(TP, FP, TN, FN)\n",
    "\n",
    "\n",
    "# making the initial y_train series into an array\n",
    "y_train_array = np.array(y_train)\n",
    "\n",
    "# calculating the false/true/negative/positive outcomes on the train lasso logistic regression\n",
    "perf_measure(y_train_array, y_predicted_l)\n",
    "\n",
    "TP = 72\n",
    "FP = 25\n",
    "TN = 281\n",
    "FN = 113\n",
    "\n",
    "fpr = FP / (FP + TN)\n",
    "tpr = TP / (TP + FN)\n",
    "\n",
    "# assuming the cut off point for the predict() is 50%!!!\n",
    "print ('The False Positive rate for the training data at a 50% threshold is ', round (fpr, 2))\n",
    "print ('The True Positive rate for the training data at a 50% threshold is ', round  (tpr, 2))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the ROC curves for your training, validation (and, if you are done, test) datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_train, train_prob_l)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# training dataset\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('ROC Training Set')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# # validation dataset \n",
    "\n",
    "validation_prob_l = log_lasso.predict_proba(X_validation)[:,1]\n",
    "fpr_v, tpr_v, threshold_v = metrics.roc_curve(Y_validation, validation_prob_l)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('ROC Validation')\n",
    "plt.plot(fpr_v, tpr_v, 'b', label = 'AUC')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threshold selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate the prevalence in the environment where your model will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All positives according to the predict function threshold are 153\n",
      "Prevalence in this environment would be 0.31\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# prevalence is equal to all the positives over the total sample\n",
    "\n",
    "total_positives =  log_lasso.predict(X_train)\n",
    "mini_df = pd.DataFrame(data = total_positives, columns = ['positive'])\n",
    "\n",
    "all_positive_on_training_set = mini_df['positive'].value_counts()[1]\n",
    "\n",
    "# is the threshold for .predict() function .5???\n",
    "print(f'All positives according to the predict function threshold are {round(all_positive_on_training_set, 2)}')\n",
    "\n",
    "prevalence = all_positive_on_training_set / len(X_train)\n",
    "\n",
    "print(f'Prevalence in this environment would be {round(prevalence, 2)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate the costs for each unit of your FPs, TNs, FNs and TPs\n",
    "**Hint:** You don't have data for this. You will have to do some research and deep thinking<br>\n",
    "**Hint 2:** think of a £ value or something else that non-technical stakeholders could relate to<br>\n",
    "**Hint 3:** They are going to be approximations and that's fine. Just create a good logic.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FPc = The cost of False Positives in this case is mostly unnecessary time and resources to analyse and help people who don't need help.\n",
    "This can create longer waiting times along with inefficiencies in terms of medical supplies and material. \n",
    "\n",
    "annual = equipment_test(£50000) + doctors_time(?) £200,000 + ongoing_unecessary_treatments £300,0000\n",
    "\n",
    "TNc =  There's no cost associated with a True statement here.\n",
    "\n",
    "FNc = This would be mostly a social cost as you'd end up not recognizing the disease when someone is actually sick.\n",
    "There's no imminent money loss for the medical facilities but society as a whole would experience health issues as most people with diabetes do not get cured in time.\n",
    "Long-run term can lead to even greater losses both from a human and economic perspective.\n",
    "\n",
    "Loss of lives(???) £10,000,000 (can have loads of repercussions but hard to quantify it).\n",
    "\n",
    "\n",
    "TPc =  Ongoing_treatments £300,000\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate your m parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " m coefficient is 0.08\n"
     ]
    }
   ],
   "source": [
    "CFP = 50000 + 20000 + 300000\n",
    "TNC = 0\n",
    "FNC = 10000000\n",
    "TPC = 300000\n",
    "\n",
    "m = ((1 - prevalence) / prevalence ) * ((CFP - TNC) / (FNC - TPC))\n",
    "\n",
    "print( f' m coefficient is {round(m,2)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate fm for each threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The fm for the .4 threshold is 0.7\n",
      " The fm for the .5 threshold is 0.58\n",
      " The fm for the .6 threshold is 0.52\n",
      " The fm for the .7 threshold is 0.41\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, threshold = metrics.roc_curve(y_train, train_prob_l)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# finding TPR and FPR for threshold 0.4\n",
    "thresh_40 = threshold[65]\n",
    "fpr_40 = fpr[65]\n",
    "tpr_40 = tpr[65]\n",
    "\n",
    "fm_40 = tpr_40 - m*fpr_40\n",
    "\n",
    "print(f' The fm for the .4 threshold is {round(fm_40,2)}')\n",
    "\n",
    "# finding TPR and FPR for threshold 0.5\n",
    "thresh_50 = threshold[46]\n",
    "fpr_50 = fpr[46]\n",
    "tpr_50 = tpr[46]\n",
    "\n",
    "fm_50 = tpr_50 - m*fpr_50\n",
    "\n",
    "print(f' The fm for the .5 threshold is {round(fm_50,2)}')\n",
    "\n",
    "# finding TPR and FPR for threshold 0.6\n",
    "thresh_60 = threshold[33]\n",
    "fpr_60 = fpr[33]\n",
    "tpr_60 = tpr[33]\n",
    "\n",
    "fm_60 = tpr_60 - m*fpr_60\n",
    "\n",
    "print(f' The fm for the .6 threshold is {round(fm_60,2)}')\n",
    "\n",
    "# finding TPR and FPR for threshold 0.7\n",
    "thresh_70 = threshold[25]\n",
    "fpr_70 = fpr[25]\n",
    "tpr_70 = tpr[25]\n",
    "\n",
    "fm_70 = tpr_70 - m*fpr_70\n",
    "\n",
    "print(f' The fm for the .7 threshold is {round(fm_70,2)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the threshold with the highest fm score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The the highest fm is the .4 threshold with 0.7\n"
     ]
    }
   ],
   "source": [
    "print(f' The the highest fm is the .4 threshold with {round(fm_40,2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the confusion matrix for your selected threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[246,  60],\n",
       "       [ 50, 135]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# selecting all patients with above .4 from the predict_proba function on the training set\n",
    "another_mini_df = pd.DataFrame(data = train_prob_l, columns =  ['probabilities'])\n",
    "\n",
    "# created another colmns with all the .4 instances\n",
    "another_mini_df['prob>4'] = (another_mini_df['probabilities'] >=.4).astype(int)\n",
    "\n",
    "# conveeting into an array\n",
    "y_pred_4 =  np.array(another_mini_df['prob>4'])\n",
    "\n",
    "# creating the confusion matrix with sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train, y_pred_4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate your alpha / power / precision / accuracy\n",
    "(Don't use any library for this exercise, in real life you can though)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha is  0.31\n",
      "Statistical Power is  0.83\n",
      "Precision is  0.8\n",
      "Accuracy is  0.78\n"
     ]
    }
   ],
   "source": [
    "# alpha is equal to false positive rate\n",
    "\n",
    "alpha = 60  / (60 + 135)\n",
    "\n",
    "# statistical power is basically the true positive rate\n",
    "stat_power = 246 / (246 + 50)\n",
    "\n",
    "# precision are the actual positive within all the people I estimated to be positive\n",
    "\n",
    "prec = 246 / (246 + 60)\n",
    "\n",
    "# accuracy is the sum of all the true positive and negative over the entire population\n",
    "\n",
    "accu = (246 + 135) /491\n",
    "\n",
    "print ('Alpha is ', round(alpha,2))\n",
    "print ('Statistical Power is ', round(stat_power,2))\n",
    "print ('Precision is ', round(prec,2))\n",
    "print ('Accuracy is ', round(accu,2))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain in non-technical terms your alpha / power / precision / accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpha is the probability of stating that someone needs treatments while actually they didn't.\n",
    "Statistical power is how much our model is good at identifying people who actually need some treatments for diabetes.\n",
    "\n",
    "Precision here would be how many times our model correctly predicted someone needed tratement when the model thought so.\n",
    "Accuracy would be how many times the model managed to identify correctly both people that needed treatment and people who didn't."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actionable problem solving recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a brief paragraph telling your stakeholders something they can **DO** to be better off based on your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Really not sure on how to interpret the coefficients of the logistic regression and also how to take actionable/meaningful insights from the ROC.\n",
    "By looking at the coefficients of the lasso model, the variable 'DiabetesPedigreeFunction' seemed to have a much greater impact than anything else.\n",
    "\n",
    "I would advise doctors to closely monitor that value but it doesn't sound really useful to be honest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
